# 存储器层次结构
## Lecture11：内存层次结构
传统无缓存的内存读取：<br>
<img src="markdown图片/屏幕截图 2023-11-16 162029.png" alt="图片alt" title="图片title"><br>
内存离寄存器过远了<br>
传统无缓存硬盘读取：<br>
1. CPU提供逻辑块地址给硬盘
2. 硬盘控制器传输信息到内存中，**这个过程cpu不会关注**
3. 硬盘控制器发送中断信息给CPU。<br>
第二步这么做的原因在于，硬盘读写速度过慢，因此硬盘读写时间CPU用来做其他事。**即某种进程阻塞**

## 如何缓解CPU速度与存储速度的不一致：
程序的局部性：程序更可能使用接近其“最近使用的数据或地址”的那些或地址。<br>
时间局部性：某时刻访问的内存地址，很近的时刻可能再次访问<br>
空间局部性：某时刻的访问地址，很近的时刻很可能访问邻近的地址<br>
例如下述程序，体现了数据和指令的时间空间局部性。
<img src="markdown图片/屏幕截图 2023-11-16 173553.png" alt="图片alt" title="图片title">
因此，我们要尽量写出适合局部性的程序，例如二维三维数组的相加。  

## 利用上述局部性，实现高速缓存
如下面的存储器层次结构：<br>
<img src="markdown图片/屏幕截图 2023-11-16 201327.png" alt="图片alt" title="图片title"><br>
每个上层从它的下一层检索数据，**家-学校-书包比喻，书包即缓存**这就是一种缓存思想：<br>
例如，可以把内存视为硬盘数据的缓存，因此在cpu读取硬盘数据期间，只有硬盘和内存的交互，cpu可以干其他事情。<br>
缓存基本原理：分块预先存储上层内存中内容：<br>
<img src="markdown图片/屏幕截图 2023-11-16 204031.png" alt="图片alt" title="图片title"><br>

cpu访问内存流程：  
命中(hit):如访问第14块，则可以把第14块直接给寄存器<br>
未命中(miss):如上图假如需要第4块内存，先发现cache中没有第4块，则cache向内存申请第4块，然后（缓存淘汰策略，如LRU）覆盖最近最少使用缓存（图中的第8块）。**这里不准确，见后面的组相练cache**<br>
缓存不命中原因：<br>
1. 冷启动时，cache为空不命中
2. 空间不命中，某一程序的工作集大于缓存容量，必然无法每个都命中
3. 冲突不命中
具体的见后。

### 对于硬盘这种放入内存是可以获知的地址，但是对于内存访问地址未知，如何把内存中更可能被访问的放入高级缓存中？
利用局部性原理，访问某一地址内存时，把那一部分内存都放入缓存中。这就是为什么上面的图按块划分的原理，必然某一时刻cpu访问的内存地址在第4块，就可以把第4块的整个都放入缓存。<br>

# cache memories
## 通用cache结构：
<img src="markdown图片/屏幕截图 2023-11-17 110141.png" alt="图片alt" title="图片title"><br>
S组，每组E行，每行为一个最小块，最小块容量为B，B有2^b个字节。其中valid bit标识当前最小块是有效的，tag

### cache read流程：
cpu要访问的内存地址为A,A在高速缓存中结构是这样的:<br>
<img src="markdown图片/屏幕截图 2023-11-17 115751.png" alt="图片alt" title="图片title"><br>
具体的，先通过中间的unsigned的s个位，确定在S组中的哪一行，然后通过标识位，匹配E行中的哪一块，然后每块有B个字节，在通过b位偏移量确定是**哪些**字节。总的来说就是一个哈希。<br>
**特别注意，这个A已经不是真正的内存地址A了，是经过地址转换的**<br>
如下图所示，注意b为偏移量：<br>
<img src="markdown图片/屏幕截图 2023-11-17 120910.png" alt="图片alt" title="图片title"><br>

### 几种cache存储命中方式：
首先，cpu寻找的内存地址，一定是要在缓存中有映射的，但是显然缓存小于内存，所以内存到缓存中里面一定会有重复，覆盖的情况。<br>
然后，具体访问的内存地址，在缓存中是否有真正存在，也是需要鉴定的，所以给缓存提供的地址是能完全映射内存的，具体的映射方式如下图所示：<br>
**下图的例子为直接映射高速缓存，也即每一个缓存索引块中只有一行**
<img src="markdown图片/屏幕截图 2023-11-17 170327.png" alt="图片alt" title="图片title"><br>
**解释**:
图中地址位有4个位，因此可以表示16个地址，但是缓存只有8个字节空间，所以具体信息如下：<br>
假设有16个字节的内存地址，1块中有两个字节，因此需要总共有8个内存块，然鹅缓存只能存4块：
1. 首先需要建立缓存地址与内存块的映射，这个由上图的索引位和标记位共同做到。另外我们记得，组索引即s，确定了缓存的分组，**本例中设定每组就一行**，每一组内部则有标记位tag，因此，缓存大小有组索引决定，即4块，标记位会标识此时是块0还是块3。最后，在一个块内部，具体的偏移则由偏移位实现。
2. 具体读的时候，先给出的是内存地址（1-16），先把该地址翻译成块索引+偏移量，然后在高速缓存里面按索引找，如果命中块（组索引和标识位均匹配）则返回，如果任意原因未命中，则需要从内存取出该块，然后**放到对应的组索引位置，视情况设定标识位tag**<br>
3. **总的来说,缓存的索引位是不会变的，是缓存块的唯一标识，tag位用于区分内存块，偏移位用于在块中区分不同的字节**<br>
4. **每块是不存储索引和偏移的，索引和偏移由硬件推得，每块存有效位，tag和字节内容。**<br>
**抖动问题**：<br>
即反复的加载两个不同的缓存，具体案例如下：<br>
<img src="markdown图片/屏幕截图 2023-11-19 163645.png" alt="图片alt" title="图片title"><br>
在上图中，假设内存64个字节，cache32个字节，那么x会占据内存前32字节，y占据后32个，然而cache地址映射，正好是32个映射内存，然后根据标记位来区分；<br>
因此，访问xy的不断发生缓存不命中。根本原因是**反复读取的不同内存块映射到了相同的缓存组**<br>

#### 另附内存地址与缓存映射的关系，以及这样设计的原因：
<img src="markdown图片/屏幕截图 2023-11-19 165052.png" alt="图片alt" title="图片title"><br>
即，如何把地址映射到cache块上，又如何在小于总内存的cache里识别内存块(位数相同，所以一定能标记识别出内存块)

### 多行缓存映射，即每一块有多行（组相连高速缓存）：
**记住一点，tag匹配，组索引搜寻由硬件完成，尤其tag匹配，越复杂的匹配硬件实现越困难，因此要做好组数量与tag数量的平衡**<br>
一组多行，减少索引组的数量，组内部增加行数，由硬件匹配行数，如下图所示：<br>
<img src="markdown图片/屏幕截图 2023-11-19 194358.png" alt="图片alt" title="图片title"><br>
如图所示，增加某一索引的行数能够减少缓存被重新读写的概率，减少指令数量，但也增加了tag匹配的难度。

### 缓存替换策略：
注意上面每一组中，只有组索引，没有tag索引，例如上图一组有两行，其实际上有4个内存会映射到这一组索引里面。而且行之间是平等的，不同tag放到哪一行都一样，也就是没有tag索引。<br>
因此我们就要考虑了，当两行满了的时候，新添加一行要如何替换旧的？<br>

## cache写操作：
多层存储架构中，写的同步性。<br>
何时把高层的缓存的东西写回低层级？<br>
两种方案，
write-through直写:一种是立即写回，即变化了就写回。这种方法一定程度违背了使用缓存的初衷。<br>
write-back写回:缓存将要被覆盖时，且被改变时写回（因此需要多一位标识是否被改过）。**注意数据同步问题，因为被覆盖之前一直是cpu和缓存交换，因此如果多核情况下，要注意那些缓存是共有的，那些是独有的**<br>

**CPU通过cache写入内存**
也会出现命中非命中问题：  
命中好说，非命中如果是冲突情况，则会发生覆盖，要写回下一级的存储。  
两种解决方式：  
1. 写分配：写不命中的情况下，加载低一层的存储进入cacha，然后写入
2. 直写：直接写入更低一层的存储中。

### 经典多核缓存系统：
<img src="markdown图片/屏幕截图 2023-11-19 204731.png" alt="图片alt" title="图片title"><br>
具体同步内容后面会讲<br>

### 如何写出缓存友好代码：
