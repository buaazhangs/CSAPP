# 并发编程
常见的并发编程问题：
<img src="markdown图片/屏幕截图 2024-03-13 213353.png" alt="图片alt" title="图片title"><br>
迭代服务器：<br>
<img src="markdown图片/屏幕截图 2024-03-13 220442.png" alt="图片alt" title="图片title"><br>
其中，客户端2的write不会阻塞，服务器的内核（TCP协议）会维护一个写入的队列，客户端2的read会阻塞。<br>
另外，客户端1一直未发出close，这导致服务器也被客户端1阻塞。
PS；服务器被阻塞情况下，仍可能允许客户端连入，这些时候客户端的connect或者read等被阻塞，客户端可连入的上线取决于主机的TCP协议。

# 三种并发编程方法
<img src="markdown图片/屏幕截图 2024-03-14 193413.png" alt="图片alt" title="图片title"><br>

## 1. 基于多进程的并发编程
多进程服务器：<br>
<img src="markdown图片/屏幕截图 2024-03-14 195103.png" alt="图片alt" title="图片title"><br>
这种并发的优劣：<br>
<img src="markdown图片/屏幕截图 2024-03-14 195635.png" alt="图片alt" title="图片title"><br>
优点：<br>
1. 实现并发多连接
2. 利用进程的私有地址空间，实现了文件描述符，全局变量的**内存**中的私有，完全隔离，**注意不是硬盘的隔离**（另外注意打开文件表是相同的**（注意是打开文件表不是文件描述符，文件描述符在fork时才是一定一样的）**）<br>

劣势：<br>
1. 开销大
2. 不易共享缓存（需要用进程间通信，或者内存映射）

## 2.基于IO多路复用的并发
假如设计一个这样的服务器，它能对服务器自己的标准输入输出交互命令做出回应，也就是说，它的功能需要能处理字节的IO，那么，假如此时自己要写入信息，另有用户想要连接，这时应优先等待哪个事件？1.先等待用户输入，那么此时用户输入会阻塞其他任务，包括任何其他连接请求2.先等待客户连接，那么此时不能响应任何一个输入命令。<br>

**文件描述符可读：**<br>
当客户端发送的字节成功到达服务器，服务器该客户端的连接描述符所绑定的socket缓存（位于内存）有数据时，就意味着读该文件描述符不会堵塞。对于非网络连接的文件描述符，即该文件描述符所对应的内存或缓存或标准IO。<br>

### 利用select，读集合和准备好读集合实事件驱动：
<img src="markdown图片/屏幕截图 2024-03-14 215219.png" alt="图片alt" title="图片title"><br>
读集合，可以理解为该集合对应的文件为内核监控的，准备好读集合，可以理解为该集合的文件描述符可读。**select持续阻塞知道读集合中有准备好读项**<br>

因此，上述利用select可以解决事件等待问题，但是，例如如果客户端连续发送大量数据，则标准输入仍得不到相应，**不管怎么说，这一服务器都得等客户端完全发送完信息，才能close，也就是说仍有可能阻塞在客户端**所以，对于这种问题解决方案是考虑更细粒度的多路复用，例如一次只从客户端或者标准IO读取一个文本行就结束。

**甚至，即使只读取一个文本行细粒度的，都有可能被阻塞，因为客户端可能只发送部分行（没有\n），因此最合理的方式是服务器读取当前文件描述符的所有可读数据**


优缺点：<br>
<img src="markdown图片/屏幕截图 2024-03-18 211249.png" alt="图片alt" title="图片title"><br>
优点：<br>
1. 单个逻辑流，单个进程，方便理解，共享地址空间，方便共享数据；方便调试。
2. 没有多进程并发服务器的上下文切换开销
缺点：<br>
1. 事件划分等因素使得代码设计更复杂
2. 实际上并没有提升时间效率
3. 因此也无法使用多核加速

## 3. 基于线程的并发
进程与线程的区别：<br>
<img src="markdown图片/屏幕截图 2024-03-19 193801.png" alt="图片alt" title="图片title"><br>
左边为进程上下文，右边为进程在内存中的空间（不删除进程不会删去），如程序段，栈，堆等。<br>
**注意其中进程context和内核context的区别：**<br>
1. 进程上下文，基本可以理解为寄存器值，在该进程运行时这些寄存器值在相应寄存器内，非该进程运行时这些寄存器存到内核的进程控制块中（位于进程内存的内核空间的内核栈）
2. 内核上下文，如页表，文件描述符秒，堆指针等，这些一直都位于进程的内核空间内，一般程序位于内核模式时需要里面的信息
3. 切换进程时的上下文切换，主要指的是把进程上下文部分，这些存在内核空间的内核栈的数据放回寄存器。
4. 内核切换本质上需要切换页表，以能够访问进程所在的物理地址，每个进程的页表的位置存储在进程控制块中**（自然的，这一部分属于全体进程共有）**，在切换进程时，将进程控制块存储的页表基址寄存器值放出来，该寄存器存储着页表的物理地址<br>
线程：<br>
<img src="markdown图片/屏幕截图 2024-03-19 193843.png" alt="图片alt" title="图片title"><br>
可以看到线程上下文基本可以视为进程上下文，以及内存中的栈，也就是说，线程，栈指针，以及这些寄存器。**实际上，线程真正独有的仅为寄存器**<br>
**理论上线程独有栈，但实际上栈依然全部位于进程的栈段，只是理论的被划分为不同的空间，因此线程上下文切换不会切换栈，只切换寄存器**
<img src="markdown图片/屏幕截图 2024-03-19 202832.png" alt="图片alt" title="图片title"><br>
线程共享所在进程的虚拟内存空间，包括代码，数据，堆等，**实际上，一个线程理论上能够访问进程中的任意位置，也就是说，包括其他线程的栈**<br>

### posix thread
1. 创建线程以及线程例程（线程的代码和本地数据）
2. 终止线程，终止其他线程
3. 等待其他线程终止<br>
   pthread_join,等待指定tid线程终止，将tid的线程例程返回的通用对象指针赋值到\*\*thread指向的位置，然后回收该线程的资源
4. 分离线程：<br>
   可结合线程：<br>
   这种线程能被其他线程回收或杀死，在回收之前，这种线程的资源是不会释放的。<br>
   分离的线程：<br>
   这种线程不能被其他线程杀死，它的内存在其终止时由内核自动释放。<br>
5. 初始化线程状态

### 基于线程的并发服务器
要点：<br>
1. 多线程程序的竞争问题，为客户端服务的对等线程实际使用的是主线程上的连接描述符，所以如果主线程的连接描述符在栈上，由于线程运行顺序不确定，就有可能主线程链接描述符会是下一个access的结果。**因此需要在主线程堆上**
只需考虑下面两个程序：<br>
while(1){
   a = 1;
}
while(1){
   a = malloc(sizeof(int));
}

2. 避免内存泄漏问题

# 同步
控制线程执行顺序的技术,如何处理多线程共享变量的问题<br>

## 多线程程序中的共享变量
<img src="markdown图片/屏幕截图 2024-03-21 203056.png" alt="图片alt" title="图片title"><br>
注意，理论上线程可以访问进程内部的任意数据，所以只要什么形式变量x被多个线程无论以什么方式引用，这个x都是共享变量。<br>
变量类型：
1. 全局变量，虚拟内存的读写区域只包含全局变量的一个实例
2. 本地栈上变量，函数内部没有static属性的变量，每个线程的栈都有它所有本地自动变量的实例
3. 本地静态变量，虚拟内存的读写区域只包含在该进程的每个本地静态变量的一个实例。

## 竞争
<img src="markdown图片/屏幕截图 2024-03-22 163137.png" alt="图片alt" title="图片title"><br>
主要原因出在寄存器写入内存（缓存）和从内存（缓存）读的不一致性。**从汇编角度看每一步的操作：**
<img src="markdown图片/屏幕截图 2024-03-24 112407.png" alt="图片alt" title="图片title"><br>

## 进度图
将n个并发线程执行模型转化为n维笛卡尔空间的轨迹。每个轴作为某个线程的进度，每一个坐标作为每个线程的某个指令。<br>
根据线程执行的原理，每一步只有一个线程向前进，但可以是任何一个线程（即不会有对角线）<br>

临界区：<br>
<img src="markdown图片/屏幕截图 2024-03-24 121240.png" alt="图片alt" title="图片title"><br>
操作共享变量的指令构成**临界区**，**这个临界区不应该和其他线程的临界区交替执行**，因此我们希望每个线程执行他自己临界区的指令时，拥有对共享变量**互斥(mutual exclusion)互相排斥**的访问。<br>
**边界**：<br>
临界区的边界是安全的，内部（不包括边界才是危险的），设想：H2H1状态，往右边走，只要不进入就没有L2，就是安全的。<br>
为了保证这种并发执行的正确实现，必须以某种方式同步<br>

## 用信号量同步线程
信号量是一个具有非负整数值的全局变量，只能由PV两个操作来处理。有二元信号量和计数信号量两种<br>
以提供互斥为目的的二元信号量常被称为互斥锁。<br>

**注意，以下两个操作都是原子的，即不可被打断。另外，P和V都会涉及到系统调用。**<br>

设s为信号量，则：<br>
**P**:若s非零，则P将s--并立即返回。如果s为0，则挂起这个线程，直到s变为非0（注意，此时属于该线程被挂起，即该线程被放到内核态的等待队列中），**注意，此时仍在P操作中**，当该线程从等待队列中被重启后（例如，V操作执行），P继续执行，执行操作为s--，然后将控制返回给调用P函数的线程。<br>
**可以把P视为，准备读**，那么只要有一个之前读的线程没有写回，就锁着。

**V**:将s++，如果此时有任何线程阻塞在P操作等待s非0，那V操作会重启其中某一个，然后该线程将s--，完成其p操作。<br>
**可以把V视为写回**

![alt text](<markdown图片/屏幕截图 2024-03-24 155817.png>)<br>
如上图，实现用信号量完成互斥。

## 利用信号量调度共享资源
### 生产者-消费者模型：
生产者线程->缓冲区->消费者线程，其中，缓冲区作为共享资源，需要保证访问的互斥性。<br>
**但是不能仅仅保证互斥访问，还需要调度对缓冲区的访问，因为生产者需要缓冲区有空间才能写入，消费者需要缓冲区有内容才读取**

这时候就需要用上二元信号量（作为互斥量）和int信号量。<br>
标准int信号量：用于判断当前缓冲区可用数量。P表示写入，为0时停止，可以用于生产者信号（空间数量）为0（无空间），或者消费者信号（产品数量）为0（无产品）。不为0时表示可用，不阻塞。<br>
V也可以表示写入，但这个V表示的是另一个P完成，如生产者写入后，V消费者信号，其加一表示有可读。消费者消费后，V生产者信号表示有空位。
**当然上述过程依然保持互斥信号的使用。**

多个生产者消费者线程情况下，PV操作依然能保证互斥的实现。

预线程并发服务器：<br>


### 读写问题
读者线程可以和所有读线程共享变量，写者线程写入时必须独占共享变量。
1. 读者优先情形，即优先解决读线程，必须完全没有读线程才进行写；即读者不会等待，除非写者已经控制了共享变量，而写者控制共享变量只有在没有读者线程执行的情况下实现。<br>

![alt text](<markdown图片/屏幕截图 2024-03-26 204755.png>)<br>

2. 写者优先情形<br>

这两种问题的解决方案会导致“饥饿”，即如果一直有读线程被OS执行，那么写线程将被无限的阻塞，或者反过来。

## 线程安全
一个函数是线程安全的：该函数被多个并发执行的线程同时调用时不会出现错误的结果。<br>
类型如下:<br>

1. 未保护共享变量
   解决方案：加入互斥锁对共享变量进行保护
2. **该函数中，有全局变量或静态局部变量保持跨越多个调用的状态，（即这些变量跟调用历史有关，会影响函数结果）**
   ![alt text](<markdown图片/屏幕截图 2024-03-28 203203.png>)<br>
   以上图函数为例：
   1. 首先其未保护共享变量，这是基本的。例如，会导致pid1执行了next更新后，还未返回函数结果，pid2又更新了next，解决方法是加互斥锁。
   2. **重要的是，也是第二类与第一类的区别在于：**，即使加了互斥锁，这个函数也是错的，因为pid2会对pid1的next进行的**加锁后变成原子的**修正，然而实际上这个修正也是不能发生。因为正常情况下，tid1的顺序为next1->next2->next3；而两个线程可能变为tid1:next1->next3;tid2:next2。这样就也是错的。
   
   解决方案:重写该函数，将状态变量存储在线程内部，如下：<br>
   ![alt text](<markdown图片/屏幕截图 2024-03-28 204131.png>)<br>
   实际上，这也是把该函数变成可重入函数
   
3. 返回“指向全局或静态变量指针”的函数，这会导致该全局变量被别的线程覆盖，即使你正在使用该函数返回的结果。<br>
   解决方案：<br>
   ![alt text](<markdown图片/屏幕截图 2024-03-28 205723.png>)
   1. 使其返回一个线程栈上的地址（由调用者传递进去），这需要修改该函数
   2. 加锁-复制-解锁技术，即如图所示，图中sharedp会被所有调用ctime的线程覆盖，但是我们将其锁住，使得同一时间只能有一个线程覆盖它，然后将其复制，返回给线程私有位置，再解锁。<br>
   **另外，注意由于我们要防止的是别的线程覆盖哪一个内存位置，因此我们需要把返回的共享变量的内存完全转移到线程栈中，也就是说，需要用深拷贝（deep copy）（不能保留一点指针）**

4. 调用了线程不安全函数的函数，实际上，如果调用了第一类和第三类函数，使用加锁-复制-解锁技术就可以避免共享变量被别的进程修改，但是第二类函数依然需要修改该线程不安全函数本身。

可重入函数：
![alt text](<markdown图片/屏幕截图 2024-03-28 211920.png>)<br>
实际上，可重入函数就是该函数被多个线程调用时，不会应用任何共享数据。也就是说，其是不需要同步的线程安全函数。<br>

## 竞争
![alt text](<markdown图片/屏幕截图 2024-03-28 211920.png>)<br>
在解引用和主线程的i++写回内存和对等线程解引用之间发生了竞争。<br>

## 死锁
程序正在等待某个永不会发生的条件。<br>
![alt text](<markdown图片/屏幕截图 2024-03-28 215431.png>)<br>
加入线程0执行P0，然后线程1执行P1，那么就死锁了<br>
![alt text](<markdown图片/屏幕截图 2024-03-28 220049.png>)<br>
可以从进度图理解死锁，可以看到，图中的死锁区域，是因为两个线程都在等待一个被P锁住的V操作。<br>
**解决方案：**当每个线程以同一顺序获得互斥锁（P）并以相反顺序（V）释放，就无死锁。

# 线程级并行
单核角度，只有多线程才是真正意义的并行执行并发程序。
## 多核CPU
结构：<br>
![alt text](<markdown图片/屏幕截图 2024-04-01 210125.png>)<br>

## 从基础多线程程序实现开始
基础的1加到n程序，两种实现方式（见课本）对比，体现了同步（PV操作的巨大耗时），线程上下文切换的巨大耗时。<br>
进一步，再考虑到甚至只利用寄存器不利用缓存的版本，会发现速度更快了<br>

## 刻画并行程序的性能
加速比：绝对加速比与相对加速比<br>
效率：加速比/线程数<br>
Amdaul法则：<br>
优化的程序执行时间T' = Tp/k+T(1-p)<br>
T为原时间，p为程序中可优化的比例，k为优化的倍数。<br>

## 实质性的并行样例
以快排为例子<br>
较大块时，划分两个线程分别进行排序：<br>
![alt text](<markdown图片/屏幕截图 2024-04-02 200702.png>)<br>
划分到足够细粒度时，可以顺序执行左右两块的排序，以减少线程开销。<br>

## 多核场景
![alt text](<markdown图片/屏幕截图 2024-04-02 204954.png>)<br>
如上图所示，实质上多核才能真正实现多线程并行程序。缓存以写回的形式返回内存，因此如果CPU不需要替换该位置的缓存时，缓存就不会写回内存，造成了如图每个线程有自己私有的变量的形式出现。<br>
![alt text](<markdown图片/屏幕截图 2024-04-02 205907.png>)<br>
需要MESI协议解决，简单来说：E表示独占，当某一线程要写到缓存时，该处缓存和相应的内存行的标志位变成E，表示此时该线程独占该内存；其余核的对应行缓存表示为变成I，表示不可用。当某线程要读的时候，对应的缓存直接从E的缓存读取，然后表示为变成S。
