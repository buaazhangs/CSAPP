# 存储器层次结构
## Lecture11：内存层次结构
传统无缓存的内存读取：<br>
<img src="markdown图片/屏幕截图 2023-11-16 162029.png" alt="图片alt" title="图片title"><br>
内存离寄存器过远了<br>
传统无缓存硬盘读取：<br>
1. CPU提供逻辑块地址给硬盘
2. 硬盘控制器传输信息到内存中，**这个过程cpu不会关注**
3. 硬盘控制器发送中断信息给CPU。<br>
第二步这么做的原因在于，硬盘读写速度过慢，因此硬盘读写时间CPU用来做其他事。**即某种进程阻塞**

## 如何缓解CPU速度与存储速度的不一致：
程序的局部性：程序更可能使用接近其“最近使用的数据或地址”的那些或地址。<br>
时间局部性：某时刻访问的内存地址，很近的时刻可能再次访问<br>
空间局部性：某时刻的访问地址，很近的时刻很可能访问邻近的地址<br>
例如下述程序，体现了数据和指令的时间空间局部性。
<img src="markdown图片/屏幕截图 2023-11-16 173553.png" alt="图片alt" title="图片title">
因此，我们要尽量写出适合局部性的程序，例如二维三维数组的相加。  

## 利用上述局部性，实现高速缓存
如下面的存储器层次结构：<br>
<img src="markdown图片/屏幕截图 2023-11-16 201327.png" alt="图片alt" title="图片title"><br>
每个上层从它的下一层检索数据，**家-学校-书包比喻，书包即缓存**这就是一种缓存思想：<br>
例如，可以把内存视为硬盘数据的缓存，因此在cpu读取硬盘数据期间，只有硬盘和内存的交互，cpu可以干其他事情。<br>
缓存基本原理：分块预先存储上层内存中内容：<br>
<img src="markdown图片/屏幕截图 2023-11-16 204031.png" alt="图片alt" title="图片title"><br>

cpu访问内存流程：  
命中(hit):如访问第14块，则可以把第14块直接给寄存器<br>
未命中(miss):如上图假如需要第4块内存，先发现cache中没有第4块，则cache向内存申请第4块，然后（缓存淘汰策略，如LRU）覆盖最近最少使用缓存（图中的第8块）。**这里不准确，见后面的组相练cache**<br>
缓存不命中原因：<br>
1. 冷启动时，cache为空不命中
2. 空间不命中，某一程序的工作集大于缓存容量，必然无法每个都命中
3. 冲突不命中
具体的见后。

### 对于硬盘这种放入内存是可以获知的地址，但是对于内存访问地址未知，如何把内存中更可能被访问的放入高级缓存中？
利用局部性原理，访问某一地址内存时，把那一部分内存都放入缓存中。这就是为什么上面的图按块划分的原理，必然某一时刻cpu访问的内存地址在第4块，就可以把第4块的整个都放入缓存。<br>

# cache memories
## 通用cache结构：
<img src="markdown图片/屏幕截图 2023-11-17 110141.png" alt="图片alt" title="图片title"><br>
S组，每组E行，每行为一个最小块，最小块容量为B，B有2^b个字节。其中valid bit标识当前最小块是有效的，tag

### cache read流程：
cpu要访问的内存地址为A,A在高速缓存中结构是这样的:<br>
<img src="markdown图片/屏幕截图 2023-11-17 115751.png" alt="图片alt" title="图片title"><br>
具体的，先通过中间的unsigned的s个位，确定在S组中的哪一行，然后通过标识位tag，匹配E行中的哪一块，然后每块有B个字节(现在的系统为64或128个字节)，在通过b位偏移量确定是**哪些**字节。总的来说就是一个哈希。<br>

**某些概念：**<br>
<img src="markdown图片/屏幕截图 2023-11-20 180302.png" alt="图片alt" title="图片title"><br>

**特别注意，这个A是经过地址转换的**<br>

**因此，一次对内存的引用，会把这附近的一行（块，行和块是一样的）（行大小现在一般为64B或128B）的都拷进更高级的缓存中，以实现局部性原理的加速**

如下图所示，注意b为偏移量：<br>
<img src="markdown图片/屏幕截图 2023-11-17 120910.png" alt="图片alt" title="图片title"><br>

### 几种cache存储命中方式：
首先，cpu寻找的内存地址，一定是要在缓存中有映射的，但是显然缓存小于内存，所以内存到缓存中里面一定会有重复，覆盖的情况。<br>
然后，具体访问的内存地址，在缓存中是否有真正存在，也是需要鉴定的，所以给缓存提供的地址是能完全映射内存的，具体的映射方式如下图所示：<br>
**下图的例子为直接映射高速缓存，也即每一个缓存索引块中只有一行**
<img src="markdown图片/屏幕截图 2023-11-17 170327.png" alt="图片alt" title="图片title"><br>
**解释**:
图中地址位有4个位，因此可以表示16个地址，但是缓存只有8个字节空间，所以具体信息如下：<br>
假设有16个字节的内存地址，1块中有两个字节，因此需要总共有8个内存块，然鹅缓存只能存4块：
1. 首先需要建立缓存地址与内存块的映射，这个由上图的索引位和标记位共同做到。另外我们记得，组索引即s，确定了缓存的分组，**本例中设定每组就一行**，每一组内部则有标记位tag，因此，缓存大小有组索引决定，即4块，标记位会标识此时是块0还是块3。最后，在一个块内部，具体的偏移则由偏移位实现。
2. 具体读的时候，先给出的是内存地址（1-16），先把该地址翻译成块索引+偏移量，然后在高速缓存里面按索引找，如果命中块（组索引和标识位均匹配）则返回，如果任意原因未命中，则需要从内存取出该块，然后**放到对应的组索引位置，视情况设定标识位tag**<br>
3. **总的来说,缓存的索引位是不会变的，是缓存块的唯一标识，tag位用于区分内存块，偏移位用于在块中区分不同的字节**<br>
4. **每块是不存储索引和偏移的，索引和偏移由硬件推得，每块存有效位，tag和字节内容。**<br>
**抖动问题**：<br>
即反复的加载两个不同的缓存，具体案例如下：<br>
<img src="markdown图片/屏幕截图 2023-11-19 163645.png" alt="图片alt" title="图片title"><br>
在上图中，假设内存64个字节，cache32个字节，那么x会占据内存前32字节，y占据后32个，然而cache地址映射，正好是32个映射内存，然后根据标记位来区分；<br>
因此，访问xy的不断发生缓存不命中。根本原因是**反复读取的不同内存块映射到了相同的缓存组**<br>

#### 另附内存地址与缓存映射的关系，以及这样设计的原因：
<img src="markdown图片/屏幕截图 2023-11-19 165052.png" alt="图片alt" title="图片title"><br>
即，如何把地址映射到cache块上，又如何在小于总内存的cache里识别内存块(位数相同，所以一定能标记识别出内存块)

### 多行缓存映射，即每一块有多行（组相连高速缓存）：
**记住一点，tag匹配，组索引搜寻由硬件完成，尤其tag匹配，越复杂的匹配硬件实现越困难，因此要做好组数量与tag数量的平衡**<br>
PS:n路组相连，意思为缓存一组有n行（块）<br>
一组多行，减少索引组的数量，组内部增加行数，由硬件匹配行数，如下图所示：<br>
<img src="markdown图片/屏幕截图 2023-11-19 194358.png" alt="图片alt" title="图片title"><br>
**这种做法真正的优化在于，同一组内不同行的待遇是一样的**<br>
**注意到此时似乎4个16字节的缓存存储了8个16字节的内存，因此对于图中的2个组而言，每个组有两行（两块），每块16字节，偏移（8字节为基准的话）为0或1**<br>
**因此，根据组索引所以存放缓存的话，（01，23，89，1011）的内存会被放到第一组，其他的放到第二组。以第一组为例，4个块在2个块的缓存空间竞争，而2个块的缓存空间是平等的，因此可以直接先存放2个块**<br>
**与直接相连缓存相比，直接相连缓存是（01，89）；（23，1011）；（45，1213）；（67，1415）；2个块在1个缓存空间竞争**<br>
如图所示，增加某一索引的行数能够减少缓存被重新读写的概率，减少指令数量，但也增加了tag匹配的难度。

### 缓存替换策略：
注意上面每一组中，只有组索引，没有tag索引，例如上图一组有两行，其实际上有4个内存会映射到这一组索引里面。而且行之间是平等的，不同tag放到哪一行都一样，也就是没有tag索引。<br>
因此我们就要考虑了，当两行满了的时候，新添加一行要如何替换旧的？<br>

## cache写操作：
多层存储架构中，写的同步性。<br>
何时把高层的缓存的东西写回低层级？<br>
两种方案，
write-through直写:一种是立即写回，即变化了就写回。这种方法一定程度违背了使用缓存的初衷。<br>
write-back写回:缓存将要被覆盖时，且被改变时写回（因此需要多一位标识是否被改过）。**注意数据同步问题，因为被覆盖之前一直是cpu和缓存交换，因此如果多核情况下，要注意那些缓存是共有的，那些是独有的**<br>

**CPU通过cache写入内存**
也会出现命中非命中问题：  
命中好说，非命中如果是冲突情况，则会发生覆盖，要写回下一级的存储。  
两种解决方式：  
1. 写分配：写不命中的情况下，加载低一层的存储进入cacha，然后写入
2. 直写：直接写入更低一层的存储中。

### 经典多核缓存系统：
<img src="markdown图片/屏幕截图 2023-11-19 204731.png" alt="图片alt" title="图片title"><br>
具体同步内容后面会讲<br>

### 获取存储器山代码：
见代码mountain.c,该代码用不同的size（验证时间局部性）和不同的跨度stride（验证空间局部性）来分析不同层级存储的读吞吐量(MB/s)<br>
从下面这张图可以看出几点:<br>
<img src="markdown图片/屏幕截图 2023-11-20 163143.png" alt="图片alt" title="图片title"><br>
1. size较小的时候，l1cache是如此的快，以至于stride变化导致的重复写入的抖动现象也非常的不明显。
2. size大起来后，需要更多的往上层进行获取，同时stride导致的空间局部性被破坏影响也会增大
3. 块大小为64个字节，因此图中stride大于64个字节以后，空间局部性彻底消失，每一个下一迭代必然未命中，此时也达到了读取速度的最低点，使用缓存的意义消失了，之后增加stride，读吞吐量也不会下降了。

### 如何写出缓存友好代码：
#### 重新排列循环以提高空间局部性：
矩阵乘法：<br>
观察分析矩阵乘法的两种循环模式，以及这两种模式的未命中率。<br>
(假设每行有（块）32个字节，矩阵值为double，矩阵行列大小远大于32.因此对于行优先存储的数组，行读取的冷启动命中率为0.25)。<br>
传统写法，b列访问，每次都miss；<br>
<img src="markdown图片/屏幕截图 2023-11-20 174344.png" alt="图片alt" title="图片title"><br>
进阶写法，bc行访问，a在最内层循环外部：<br>
<img src="markdown图片/屏幕截图 2023-11-20 174132.png" alt="图片alt" title="图片title"><br>

#### 改善时间局部性：
使用blocking（分块）改善时间局部性：

